# 附录C：核心工具速查手册 (Tooling Quick Reference)

在实际项目中，我们经常需要重复编写一些模式化的代码。这个速查手册为你提供了一些本书核心工具库的常用代码片段，希望能帮你节省时间，将精力聚焦在业务逻辑上。

### 1. Scikit-learn: 训练一个分类器

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split

# 假设 X是文本列表, y是标签列表
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建一个流水线
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('classifier', LogisticRegression())
])

# 训练模型
pipeline.fit(X_train, y_train)

# 评估模型
accuracy = pipeline.score(X_test, y_test)
print(f"模型准确率: {accuracy}")

# 进行预测
new_texts = ["这是一个需要分类的新文本"]
predictions = pipeline.predict(new_texts)
print(f"预测结果: {predictions}")
```

### 2. LangChain: 构建一个基础的RAG链

```python
# 需要安装: langchain, langchain_openai, langchain_community
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# 1. 初始化模型和嵌入
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
embeddings = OpenAIEmbeddings()

# 2. 创建一个向量数据库 (假设已有文本块`docs`)
vectorstore = FAISS.from_documents(docs, embeddings)
retriever = vectorstore.as_retriever()

# 3. 创建Prompt模板
prompt = ChatPromptTemplate.from_template("""
仅根据提供的上下文来回答问题:
<context>
{context}
</context>
问题: {input}
""")

# 4. 创建并运行链
document_chain = create_stuff_documents_chain(llm, prompt)
retrieval_chain = create_retrieval_chain(retriever, document_chain)

response = retrieval_chain.invoke({"input": "你的问题是什么？"})
print(response["answer"])
```

### 3. LangGraph: 构建一个简单的Agent

```python
# 需要安装: langgraph, langchain, langchain_openai
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator

# 1. 定义状态
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]

# 2. 定义Agent节点
def my_agent_node(state):
    # ... 在这里调用LLM或执行你的Agent逻辑
    response_message = {"role": "assistant", "content": "这是Agent的回答"}
    return {"messages": [response_message]}

# 3. 定义工作流图
workflow = StateGraph(AgentState)
workflow.add_node("agent", my_agent_node)
workflow.set_entry_point("agent")
workflow.add_edge("agent", END)

# 4. 编译并运行
graph = workflow.compile()
initial_state = {"messages": [{"role": "user", "content": "你好"}]}
final_state = graph.invoke(initial_state)

print(final_state['messages'][-1]['content'])
``` 