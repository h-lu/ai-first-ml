# 附录A：关键术语表 (Glossary)

在这里，我们为你梳理了全书中出现的核心术语，并提供了简洁、直观的解释，希望能帮助你巩固记忆、构建清晰的知识体系。

<br>

**A**

:   **AI Agent (AI智能体)**
    :   一个能够感知环境、进行自主决策和执行动作的计算实体。与传统的聊天机器人不同，Agent不仅“会说”，还能通过调用工具（APIs）来“做事”，以完成复杂任务。

:   **Alignment Engineering (对齐工程)**
    :   指通过一系列技术（如SFT, RM, DPO等），使大型语言模型的行为、价值观和目标与人类的意图和偏好保持一致的过程。其目的是让AI变得更有用、更诚实、也更无害。

:   **Approximate Nearest Neighbor (ANN, 近似最近邻搜索)**
    :   一种在海量高维数据（如向量）中快速找到近似最相似项的算法。它是向量数据库实现毫秒级响应的核心技术，通过牺牲一点点精度来换取巨大的速度提升。

**C**

:   **Chunking (文本分块)**
    :   在RAG流程中，将长文档切分成更小的、语义完整的文本块的过程。合理的`Chunking`策略对于提升检索质量至关重要。

**D**

:   **Direct Preference Optimization (DPO, 直接偏好优化)**
    :   一种比PPO更轻量、更稳定的LLM对齐技术。它跳过了显式训练奖励模型的步骤，直接利用人类的偏好数据（例如，回答A比回答B好）来微调模型，使其更倾向于生成符合人类偏好的内容。

**E**

:   **Embedding (嵌入向量)**
    :   一种将文本、图片等非结构化数据，转换为稠密的、低维的、能够捕捉其语义信息的数字向量表示的技术。它是现代AI的基石，让机器能够以数学的方式理解和计算“意义”的相似度。

**F**

:   **Fine-tuning (微调)**
    :   在预训练模型（Pre-trained Model）的基础上，使用特定的、小规模的数据集继续训练模型，使其适应特定任务或领域的过程。SFT和DPO都是微调的具体形式。

**H**

:   **Human-in-the-Loop (人机协同)**
    :   在自动化系统（尤其是AI系统）的关键决策点，引入人类进行审核、确认或干预的机制。这是确保AI Agent执行高风险操作（如删除数据、执行付款）时安全可控的核心设计模式。

**L**

:   **LangChain / LangGraph**
    :   一个用于构建、编排和部署LLM应用的开源框架。`LangChain`提供了丰富的组件，而`LangGraph`则专注于以“图”的形式构建更复杂、更可控的AI Agent和多Agent工作流。

**P**

:   **Prompt Engineering (提示工程)**
    :   设计和优化输入给AI模型（尤其是LLM）的提示（Prompt），以引导其产生更准确、更相关、更符合预期的输出的艺术和科学。

:   **Proximal Policy Optimization (PPO, 近端策略优化)**
    :   一种经典的强化学习算法，被广泛用于LLM的对齐训练。它通过一个“演员”（Policy Model）和一个“裁判”（Reward Model）的互动，让AI在不断的探索和试错中，学习如何最大化奖励，从而生成更好的回答。

**R**

:   **Retrieval-Augmented Generation (RAG, 检索增强生成)**
    :   一种让LLM能够基于外部私有知识库来回答问题的技术框架。它通过“检索（Retrieval）”从知识库（如向量数据库）中找到相关信息，并将其作为上下文（Context）提供给LLM，以“增强（Augmented）”其生成（Generation）的答案的准确性和事实性。

:   **Reward Model (RM, 奖励模型)**
    :   在对齐工程中，一个专门用来模拟人类偏好的模型。它的任务不是生成文本，而是给任何一个由LLM生成的回答打一个“品味分”（即奖励分数），判断其“好坏”程度。这个模型是PPO算法的核心驱动力。

**S**

:   **Supervised Fine-tuning (SFT, 监督微调)**
    :   对齐工程的第一步。使用高质量的、格式类似于“指令-回答”的标注数据集来微调LLM，旨在向模型快速注入特定领域的知识和遵循指令的能力。

**T**

:   **Token (词元)**
    :   文本被AI模型处理时的基本单位。一个Token可以是一个单词、一个词根，甚至是一个标点符号。LLM的输入长度和计算成本通常都与Token数量直接相关。

**V**

:   **Vector Database (向量数据库)**
    :   一种专门为存储、索引和高效查询海量Embedding向量而设计的数据库。它通常使用近似最近邻（ANN）算法来实现对语义相似内容的高速检索。