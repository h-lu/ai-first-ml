# 10.4 Practice: 指挥AI调用模型将文档转化为向量

理论学习已经结束，现在是时候亲自动手，将文本真正地转化为向量了。

在这个实践环节，我们将完成RAG蓝图"离线处理流程"中的关键两步：**文本分块 (Splitting)** 和 **文本向量化 (Embedding)**。

我们将使用一个非常强大且流行的句向量库`sentence-transformers`。它封装了大量预训练好的、顶尖的句向量模型，让我们只需几行代码，就能调用这些复杂的模型。

## AI协同实践：一个指令剧本

请打开你的AI编程助手（或一个Jupyter Notebook），跟随下面的"指令剧本"，向你的AI伙伴发出指令，一步步完成整个流程。

---

### 第一幕：安装与准备

:::{.callout-caution title="第一步：请求AI给出安装指令" icon="fas fa-download"}
**👤 你的指令:**

> "你好，我准备开始一个使用句向量的项目。请给我一条使用pip安装`sentence-transformers`库的命令。"
:::

**🤖 AI的预期回答:**
当然，请在你的终端中运行以下命令：
```bash
pip install sentence-transformers
```
同时，为了方便后续的文本处理，我们最好也安装`scikit-learn`，它里面包含了一些方便的文本分割工具。
```bash
pip install -U scikit-learn
```

---

### 第二幕：加载预训练模型

:::{.callout-note title="第二步：请求AI编写模型加载代码" icon="fas fa-brain"}
**👤 你的指令:**

> "太棒了，库已安装。现在请帮我编写一段Python代码。我需要：
> 1.  从`sentence_transformers`库中导入`SentenceTransformer`类。
> 2.  加载一个预训练好的句向量模型。我听说`all-MiniLM-L6-v2`是一个很不错的入门模型，它在性能和速度上取得了很好的平衡。请帮我初始化这个模型，并赋值给一个名为`embedding_model`的变量。"
:::

**🤖 AI的预期回答:**
好的，这是一个非常好的模型选择。下面是加载模型的代码：

```python
# 导入SentenceTransformer类
from sentence_transformers import SentenceTransformer

# 指定要加载的模型名称
# all-MiniLM-L6-v2 是一个在大量文本上训练过的、通用的句向量模型。
# 首次运行时，它会自动从Hugging Face模型中心下载模型文件（可能需要一些时间）。
model_name = 'all-MiniLM-L6-v2'

# 加载模型
embedding_model = SentenceTransformer(model_name)

print("模型加载成功！")
print(embedding_model)
```

---

### 第三幕：文本分块与向量化

这是我们的核心任务。我们需要将一篇长文档，先切分成小块，然后将每个小块都转换为向量。

:::{.callout-tip title="第三步：请求AI编写文本处理与向量化函数" icon="fas fa-cogs"}
**👤 你的指令:**

> "非常棒！现在是核心环节。我有一段模拟的长文档文本。请帮我编写一个Python函数，名为`embed_document`。
>
> **这个函数需要接收两个参数：**
> 1. `text`：一个字符串，代表要处理的长文档。
> 2. `model`：我们刚刚加载的`embedding_model`。
>
> **函数内部需要完成以下步骤：**
> 1.  使用`sklearn.text.RecursiveCharacterTextSplitter`来将长文本分割成小块（Chunk）。请设置`chunk_size`为200（每个块最多200个字符），`chunk_overlap`为20（块与块之间有20个字符的重叠，以保证语义连续性）。
> 2.  调用`model.encode()`方法，将分割好的所有文本块一次性地全部转换为向量。
> 3.  **最终返回一个包含所有文本块向量的列表。**
>
> 请为这个函数添加清晰的注释，并给我一个完整的、可运行的示例，包括如何定义示例文本和如何调用这个函数。"
:::

**🤖 AI的预期回答:**
这是一个非常典型的RAG预处理流程。下面是完整的代码实现：

```python
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.text import RecursiveCharacterTextSplitter

# --- 1. 加载预训练模型 ---
# 我们复用之前加载好的模型
model_name = 'all-MiniLM-L6-v2'
embedding_model = SentenceTransformer(model_name)
print("模型加载成功！")

# --- 2. 准备示例文本 ---
# 这是一段模拟的、关于RAG的介绍性长文本
long_text = """
Retrieval-Augmented Generation (RAG) is a powerful technique that combines the strengths of large language models (LLMs) with external knowledge retrieval.
The core idea is to retrieve relevant information from a knowledge base before generating a response.
This approach helps to reduce hallucinations, improve factual accuracy, and allow the model to use up-to-date information.
The process typically involves a retriever component that searches for relevant documents or passages, and a generator component (the LLM) that uses this information to craft a final answer.
Vector databases are often used to store and efficiently search through the embedded knowledge.
By grounding the LLM's responses in external data, RAG makes AI systems more reliable and trustworthy.
"""

# --- 3. 定义文本处理与向量化函数 ---
def embed_document(text, model):
    """
    将长文档分割成块，并使用指定模型将每个块转换为向量。

    参数:
    text (str): 要处理的长文档文本。
    model (SentenceTransformer): 用于生成向量的预训练模型。

    返回:
    list: 一个包含所有文本块对应向量的列表。
    """
    # 初始化文本分割器
    # chunk_size 定义了每个块的最大字符数。
    # chunk_overlap 定义了块之间的重叠字符数。
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    
    # 分割文本
    chunks = text_splitter.split_text(text)
    
    print(f"原始文本被分割成了 {len(chunks)} 个块：")
    for i, chunk in enumerate(chunks):
        print(f"块 {i+1}: {chunk}")
    
    # 使用模型对所有文本块进行向量化
    # model.encode() 是一个非常高效的方法，可以一次性处理一个文本列表。
    embeddings = model.encode(chunks)
    
    return embeddings

# --- 4. 调用函数并检查结果 ---
document_embeddings = embed_document(long_text, embedding_model)

print(f"\n成功生成了 {len(document_embeddings)} 个向量。")

# 我们可以检查第一个向量的形状和内容
first_embedding = document_embeddings[0]
print(f"第一个向量的维度是: {first_embedding.shape}")
print(f"第一个向量的前5个值是: {first_embedding[:5]}")

# 将所有向量组合成一个NumPy矩阵
embedding_matrix = np.array(document_embeddings)
print(f"\n所有向量组成的矩阵形状为: {embedding_matrix.shape}")
```

## 本节小结

恭喜你！你已经成功地完成了我们RAG系统中最核心的技术环节之一。

### 🎯 核心收获
1.  **一个实用的代码片段**: 你获得了一个可以直接复用的Python函数，它整合了**文本分块**和**句向量生成**这两个关键步骤。
2.  **掌握一个核心库**: 你学会了如何使用`sentence-transformers`库来加载预训练模型，并调用`.encode()`方法来执行向量化。
3.  **完成RAG蓝图的关键一步**: 你亲手实现了RAG"离线处理流程"中的核心部分，为我们下一章构建向量数据库做好了数据准备。

### 🤔 为何重要
"纸上得来终觉浅，绝知此事要躬行"。通过亲手编写并运行代码，你将理论知识转化为了实际的技能。你不再只是"知道"Embedding是什么，而是"会用"Embedding来处理你自己的文本数据。

我们现在拥有了一批高质量的、蕴含语义的文档向量。但它们还只是静静地躺在内存里。在下一章，我们将学习如何为这些向量建立一个高效的"记忆宫殿"——向量数据库，让它们能够被随时、快速地检索。 