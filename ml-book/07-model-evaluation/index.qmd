# 第7章 “我的模型不够好？”——精通评估与迭代 {#sec-model-evaluation}

> “如果你无法衡量它，你就无法改进它。”
>
> --- 彼得·德鲁克 (Peter Drucker)

在上一章，我们成功训练了第一个逻辑回归分类器，并得到了一个令人鼓舞的准确率，比如85%。这感觉像是一个巨大的胜利！我们的“AI质检员”似乎已经可以上岗了。

但是，一个资深的项目总监会在这时保持冷静，并提出一系列尖锐的问题：
-   “这个85%的准确率是怎么分布的？我们是不是把99%的‘优质内容’都识别对了，但只识别出了10%的‘有害内容’？”
-   “在所有被我们标记为‘有害’的内容里，有多少是真的有害，有多少是误判？每一次误判都可能导致一个无辜的创作者被惩罚。”
-   “我们有没有漏掉真正的‘有害’内容？每漏掉一个，都可能对社区造成伤害。”

这些问题都指向了一个核心议题：**单一的准确率指标是远远不够的，甚至可能具有误导性。**

欢迎来到模型评估的“精修课”。在本章，你将学会如何像一位专业的机器学习工程师一样，全方位、多角度地审视和评估你的模型。

我们即将从“我的模型能用”的阶段，迈向“我确切地知道我的模型好在哪里，又差在哪里”的更高层次。准备好戴上数据科学家的“放大镜”，仔细审视你的AI模型了吗？ 