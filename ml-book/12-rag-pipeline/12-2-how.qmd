# 12.2 How: 与AI共同设计核心的Prompt模板

::: {.callout-note title="与AI的探索之旅"}
**你 (产品经理)**:

> 你好。我们正在构建一个RAG问答系统。我已经能从向量数据库里，根据用户的问题，检索出几个最相关的文档片段了。现在我该怎么做？如何让LLM利用这些片段来回答问题？

**AI技术顾问**:

> 这是一个非常关键的步骤！我们可以设计一个**Prompt模板**，把检索到的文档片段（我们称之为`context`）和用户的原始问题（`question`）都“喂”给LLM。
>
> 最简单的想法可能是这样的：
>
> ```
> 这是相关资料：{context}
>
> 根据以上资料，回答这个问题：{question}
> ```
>
> 你觉得这个模板怎么样？

**你**:

> 嗯...看起来太简单了。如果LLM知道的知识恰好和`context`里的不一样，或者`context`里根本就没有答案，它会不会利用自己内部的知识来回答，甚至开始“胡说八道”？我们希望它成为一个忠实的“客服”，而不是一个爱自由发挥的“创意作家”。

**AI技术顾问**:

> 你的顾虑完全正确！这正是Prompt Engineering的核心挑战之一——**约束**。我们必须在Prompt中明确地给LLM“立规矩”。
>
> 让我们来迭代一下，增加一些关键的约束条件。你觉得下面这个版本怎么样？
>
> ```
> **请只根据下面提供的上下文信息来回答问题。**
> **如果上下文中没有足够的信息来回答问题，请直接说“根据我现有的资料，无法回答这个问题”，不要试图编造答案。**
>
> ---
> **上下文:**
> {context}
> ---
>
> **用户问题:**
> {question}
> ```
>
> 你看，我们增加了两条非常强硬的规则。

**你**:

> 这个版本好多了！它非常明确地限制了信息的来源，并且给出了找不到答案时的“退路”。但我还想让它的角色更清晰一点，让它的回答语气更专业、更像一个真正的助手。

**AI技术顾问**:

> 绝佳的想法！我们可以通过“角色扮演”来进一步优化它。这是我们的最终版本，它融合了我们所有的思考：
>
> ```
> **你是一个专业的AI知识库助手。**
>
> 你的任务是根据下面提供的【上下文】信息，简洁并准确地回答用户的【问题】。
>
> **规则:**
> 1.  严格基于【上下文】进行回答，不要依赖任何外部知识。
> 2.  如果【上下文】没有提供足够的信息，或者与问题无关，必须直接回答：“根据我现有的资料，无法回答这个问题。”
> 3.  回答应保持客观、中立，不要包含个人观点或猜测。
>
> ---
> **【上下文】:**
> {context}
> ---
>
> **【问题】:**
> {question}
> ```
>
> 这个模板怎么样？我们定义了它的**角色**，明确了它的**核心任务**，并制定了严格的**行为准则（规则）**。这就像是给了这位AI助手一份清晰的“岗位说明书”。

**你**:

> 完美！这份“岗位说明书”非常清晰。有了它，我就能更有信心地将任务交给LLM了。在下一节，我们就来详细拆解一下这份说明书的每一部分，理解其背后的“设计思想”。
:::
