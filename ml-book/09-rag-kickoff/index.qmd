# 第9章 项目启动：在海量文档中"海底捞针" {#sec-rag-kickoff}

> "信息就在那里，只是没有被连接起来。"
>
> --- 史蒂夫·乔布斯 (Steve Jobs)

在第一部分中，我们成功地训练了一个"质检员"模型，让机器学会了分类。我们经历了一次从"编程新手"到"传统机器学习应用者"的思维跃迁。现在，欢迎来到第二次思维跃迁的起点。

我们将挑战一个更宏大、也更接近当前技术前沿的场景：**如何让大语言模型（LLM）能够基于我们自己的私有知识库，来提供精准、可靠的问答服务？**

如果说标准的大模型是一个博学但没有特定公司记忆的"超级大脑"，那么我们这部分的目标，就是为这个大脑外挂一块"专属硬盘"，里面装着我们自己独有的、可信的知识。

这项技术，就是我们第二部分要构建的核心项目——**检索增强生成（Retrieval-Augmented Generation, RAG）**。它代表了将LLM从一个"通用聊天工具"转变为一个"企业级赋能引擎"的关键一步。

准备好从"使用模型"迈向"编排和封装模型"的更高层次了吗？让我们深入第一线的场景，看看这个挑战为何如此重要。 